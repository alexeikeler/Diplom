import spacy
from keybert import KeyBERT

doc = """
Трансфо́рмер (англ. Transformer) — це модель глибинного навчання, яка переймає механізм уваги, роздільно зважуючи важливість кожної частини даних входу. Її використовують переважно в області обробки природної мови (ОПМ)[1] та в комп'ютерному баченні (КБ).[2]

Як і рекурентні нейронні мережі (РНМ), трансформери призначено для обробки послідовних даних входу, таких як природна мова, для таких задач як переклад[en] та реферування тексту. Проте, на відміну від РНМ, трансформери оброблюють дані не обов'язково послідовно. Радше, механізм уваги забезпечує контекст для будь-якого положення в послідовності входу. Наприклад, якщо дані входу є реченням природної мови, то трансформерові не потрібно обробляти його початок, перш ніж взятися за обробку його кінця. Він, радше, визначає контекст, який надає значення кожному слову в цій послідовності. Ця властивість уможливлює набагато більше розпаралелювання, ніж РНМ, і відтак знижує тривалості тренування.[1] 
      """
nlp = spacy.load("uk_core_news_lg")
kw_model = KeyBERT(model=nlp)
keywords = kw_model.extract_keywords(doc)
print(keywords)